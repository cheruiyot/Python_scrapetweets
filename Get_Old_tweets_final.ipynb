{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install GetOldTweets3 if you don't already have the package\n",
    "# !pip install GetOldTweets3\n",
    "\n",
    "# Imports\n",
    "import GetOldTweets3 as got\n",
    "import pandas as pd\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "\n",
    "#alwaysimport this for every pyspark analytics\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
    "#sc = pyspark.SparkContext(conf=conf)\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "\n",
    "text_query = 'COVID symptoms'\n",
    "count = 7000\n",
    "geocode=\"Paris\"\n",
    "\n",
    "# Function that pulls tweets based on a general search query and turns to csv file\n",
    "\n",
    "# Parameters: (text query you want to search), (max number of most recent tweets to pull from)\n",
    "\n",
    "def text_query_to_csv(text_query, count):\n",
    "    # Creation of query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query).setMaxTweets(count).setNear(geocode)\n",
    "    #.setSince(newest_date1).setUntil(newest_date1)\n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    # Creating list of chosen tweet data\n",
    "    text_tweets = [[tweet.date, tweet.text,tweet.id,tweet.username,tweet.geo] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text','TweetID','username','geo'])\n",
    "    \n",
    "    \n",
    "    # Createspark spark dataframe\n",
    "    tweets_df_spark = spark.createDataFrame(tweets_df)\n",
    "\n",
    "    # Converting tweets dataframe to csv file\n",
    "    #tweets_df_spark.to_csv('C:\\\\Users\\\\brono\\\\First_batch\\\\Tweets19.csv',index = False,header=True)\n",
    "    tweets_df_spark.coalesce(1).write.save(path='C:\\\\Users\\\\brono\\\\First_batch\\\\Finalextract2.csv', format='csv', mode='append', inferSchema = True)\n",
    "    \n",
    "    Finaldf = spark.read.csv(\"C:\\\\Users\\\\brono\\\\First_batch\\\\Finalextract2.csv\", inferSchema = True, header = True)\n",
    "    Finaldf = Finaldf.dropDuplicates(subset=['TweetID'])\n",
    "    \n",
    "    Finaldf.sort(\"TweetID\").coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"C:\\\\Users\\\\brono\\\\First_batch\\\\Cleaned_data.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
